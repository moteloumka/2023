{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d0380f",
   "metadata": {},
   "source": [
    "# Homework 2 (HW2)\n",
    "By the end of this homework, we expect you to be able to:\n",
    "\n",
    "- Preprocess data and make it amenable to statistical analysis and machine learning models;\n",
    "- Train and test out-of-the-box machine learning models in Python;\n",
    "- Carry out simple multivariate regression analyses;\n",
    "- Use techniques to control for covariates;\n",
    "- Conduct an observational study and reason about its results.\n",
    "\n",
    "---\n",
    "\n",
    "- Homework release: Fri 17 Nov 2023\t\n",
    "\n",
    "- **Homework Due**: Fri 01 Dec 2023, 23:59\t\n",
    "\n",
    "- Grades released: Mon 11 Dec 2023\t\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Some rules\n",
    "1. You are allowed to use any built-in Python library that comes with Anaconda. If you want to use an external library, you may do so, but must justify your choice.\n",
    "\n",
    "2. Make sure you use the `data` folder provided in the repository in read-only mode. (Or alternatively, be sure you don’t change any of the files.)\n",
    "\n",
    "3. Be sure to provide a concise textual description of your thought process, the assumptions you made, the solution you implemented, and explanations for your answers. A notebook that only has code cells will not suffice.\n",
    "\n",
    "4. For questions containing the **/Discuss:/** prefix, answer not with code, but with a textual explanation **(in markdown)**.\n",
    "\n",
    "5. Back up any hypotheses and claims with data, since this is an important aspect of the course.\n",
    "\n",
    "6. Please write all your comments in **English**, and use meaningful variable names in your code. Your repo should have a single notebook (plus the required data files) in the master/main branch. **If there are multiple notebooks present, we will not grade anything.**\n",
    "\n",
    "7. We will **not run your notebook for you!** Rather, we will grade it as is, which means that only the results contained in your evaluated code cells will be considered, and we will not see the results in unevaluated code cells. Thus, be sure to hand in a **fully-run and evaluated notebook**. In order to check whether everything looks as intended, you can check the rendered notebook on the GitHub website once you have pushed your solution there.\n",
    "\n",
    "8. In continuation to the previous point, interactive plots, such as those generated using the `plotly` package, should be strictly avoided!\n",
    "\n",
    "9. Make sure to print results and/or dataframes that confirm you have properly addressed the task.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68937ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T17:54:27.233757Z",
     "start_time": "2023-11-17T17:54:26.757026Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# regression / matching\n",
    "import statsmodels.formula.api as smf\n",
    "import networkx as nx\n",
    "\n",
    "# machine lerning\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04befc",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "After two years, the EPFL Baseball Club is broke. The new Dean transferred all funds to EPFL's new poster child: its super-competitive Pétanque club. After struggling so much to learn about baseball, you have unfortunately been laid off...\n",
    "\n",
    "*(...) 1 month after, you manage to get another job (!) (...)*\n",
    "\n",
    "Congratulations! You have just been hired as a data scientist at the Association for Computational Linguistics (ACL), a professional organization for people working on natural language processing. The ACL organizes several of the top conferences and workshops in the field of computational linguistics and natural language processing.\n",
    "Your boss, Dr. Tiancheng, knows of your expertise in observational studies and asks you to investigate a question that’s been bothering everyone who has ever submitted a paper to a conference: should I spend time on writing rebuttals?\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Rebuttals, conferences, and getting your papers accepted\n",
    "\n",
    "Rebuttals in ACL (Association for Computational Linguistics) conferences and in many other academic conferences are an important part of the peer-review process. They allow authors of submitted papers to respond to the reviews and comments provided by the reviewers before a final decision is made regarding the acceptance of the paper. Here's how the rebuttal process typically works in ACL conferences:\n",
    "\n",
    "- Paper Submission: Authors submit their research papers to the ACL conference for review. These papers present novel research findings in computational linguistics, natural language processing, and related areas.\n",
    "- Peer Review: The papers undergo a peer-review process after the initial submission. The program committee or reviewers are experts in the field who evaluate the papers based on their quality, significance, novelty, methodology, and other relevant criteria. They provide comments and scores for each paper.\n",
    "- Rebuttal Period: After receiving the reviews, authors are given a specific period (usually around a week) to write a rebuttal. The rebuttal is a formal response to the reviewers' comments. It allows authors to clarify misunderstandings, address concerns, and provide additional information to support their paper's quality. \n",
    "- Final Review: After receiving the rebuttals, the reviewers may reconsider their initial assessments in light of the authors' responses. Reviewers may choose to maintain or adjust their reviews and scores based on the quality and effectiveness of the author's rebuttal.\n",
    "- Final Decision: The program committee or conference organizers consider the initial reviews/scores, rebuttals, and revised reviews/scores to make a final decision on the acceptance of the papers. The decision can be acceptance, rejection, or conditional acceptance with a request for revisions.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Data\n",
    "\n",
    "- `tmp_id`: Unique identifier for each paper in the format \"P{number}\".\n",
    "- `status`: Accept or Reject.\n",
    "- `submission_type`: Short vs. Long (papers can have different lengths). We do not use this column in this homework. \n",
    "- `track`: Track to which the paper was submitted, broadly speaking, the \"topic\" of the paper.\n",
    "- `scores_before`: Scores received before rebuttal. This is a nested JSON with many fields, but we will use only the \"overall\" score for the homework. \n",
    "- `scores_after`: Scores received after rebuttal. This is a nested JSON with many fields, but we will use only the \"overall\" score for the homework.\n",
    "- `had_rebuttal`: True or False.\n",
    "\n",
    "\n",
    "Note that: \n",
    " - reviews are assigned numbers, e.g., \"2\";\n",
    " - papers can have different numbers of reviews;\n",
    " - review numbers are arbitrary, e.g., `P1` in the dataframe has two reviews numbered \"2\" and \"3\" (but no review \"1\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1538, 6)\n"
     ]
    }
   ],
   "source": [
    "# Read the .json file and create a dataframe\n",
    "df = pd.read_json('./data/acl18_v1_numerical_final.json')\n",
    "\n",
    "#drop column submission_type\n",
    "df = df.drop(columns=['submission_type'])\n",
    "\n",
    "df['scores_before'] = df['scores_before'].apply(lambda x : {key: value['scores']['overall_score'] for key, value in x.items()})\n",
    "df['scores_after'] = df['scores_after'].apply(lambda x : {key: value['scores']['overall_score'] for key, value in x.items()})\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28074a9c",
   "metadata": {},
   "source": [
    "## Task 1 (10 pts): Get to Know Your Data\n",
    "\n",
    "As a good data scientist, you first load the data and perform some small sanity checks on it.\n",
    "\n",
    "- You are expected to continuously alter your dataframe as you complete the tasks. E.g., if you are asked to filter the data in a specific task, continue using the filtered dataset in the subsequent tasks.\n",
    "- When we tell you to \"print the dataframe,\" make sure you print it in a way that shows the total number of rows and columns in it (`display(df)` should suffice)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ab063",
   "metadata": {},
   "source": [
    "**1.1** Load the dataset containing ACL reviews into memory using pandas. \n",
    "- For each paper, create columns `overall_score_before_avg` and `overall_score_after_avg` containing the average (overall) scores before and after rebuttal.\n",
    "- For each paper, create columns `overall_score_before_std` and `overall_score_after_std` containing the standard deviation of the overall scores before and after the rebuttal.\n",
    "- Print the four newly created columns for paper `P17`.\n",
    "- Print the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overall_score_before_avg'] = df['scores_before'].apply(lambda x: np.mean(list(x.values())))\n",
    "df['overall_score_before_std'] = df['scores_before'].apply(lambda x: np.std(list(x.values())))\n",
    "df['overall_score_after_avg'] = df['scores_after'].apply(lambda x: np.mean(list(x.values())))\n",
    "df['overall_score_after_std'] = df['scores_after'].apply(lambda x: np.std(list(x.values())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0075ebff",
   "metadata": {},
   "source": [
    "**1.2** Create a single plot with 14 inches of width and 4 inches of height. The plot should contain two panels: \n",
    "- **Panel A**: The distribution of `overall_score_before_avg` for papers that were accepted and papers that were rejected.\n",
    "- **Panel B**: The distribution of `overall_score_before_avg` for papers that had rebuttals vs. papers that did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "# Panel A: Distribution of overall_score_before_avg for accepted and rejected papers\n",
    "plt.subplot(1, 2, 1)\n",
    "accepted_data = df[df['status'] == 'Accept']['overall_score_before_avg']\n",
    "rejected_data = df[df['status'] == 'Reject']['overall_score_before_avg']\n",
    "sns.histplot(data=accepted_data, kde=True, label='Accepted', color='blue', alpha=0.5)\n",
    "sns.histplot(data=rejected_data, kde=True, label='Rejected', color='orange', alpha=0.5)\n",
    "plt.title('Panel A: Distribution of overall_score_before_avg\\nfor Accepted and Rejected Papers')\n",
    "plt.xlabel('Overall Score Before Average')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "# Panel B: Distribution of overall_score_before_avg for papers with and without rebuttals\n",
    "plt.subplot(1, 2, 2)\n",
    "with_rebuttals_data = df[df['had_rebuttal'] == 1]['overall_score_before_avg']\n",
    "without_rebuttals_data = df[df['had_rebuttal'] == 0]['overall_score_before_avg']\n",
    "sns.histplot(data=with_rebuttals_data, kde=True, label='With Rebuttals', color='green', alpha=0.5)\n",
    "sns.histplot(data=without_rebuttals_data, kde=True, label='Without Rebuttals', color='red', alpha=0.5)\n",
    "plt.title('Panel B: Distribution of overall_score_before_avg\\nfor Papers with and without Rebuttals')\n",
    "plt.xlabel('Overall Score Before Average')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea160c7",
   "metadata": {},
   "source": [
    "**1.3** **/Discuss/:** If you know a paper had a rebuttal, is it more or less likely that it was accepted? Does this mean that rebuttals help papers get accepted? Explain why or why not, providing a concrete example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **E(overall score before avarage|with rebuttals) > E(overall score before avarage|without rebuttals)**\n",
    "\n",
    "- This is the information we get from pannel B. Pannel A on the other hand, gives us the notion of **higer avg before rebutal => higher chances to get accepted**. Thus, having the inforrmation that a paper had a rebutal could indicate that it is more likeley to be rated high and thus more likeley to be accepted.\n",
    "\n",
    "- This doesn't directly prove that rebuttles help papers get accepted. As we can see from Panel B, the papers that tend to have rebuttles are those that are rated well enough to start with. Those that don't gete poor scores and most likeley prefer rewriting the paper and trying their luck next time. Thus, the presence of a rebuttle is a way, an indicator of the confidence of a papers autor in their own work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87836f37",
   "metadata": {},
   "source": [
    "**1.4** Print the percentage of rebuttals per track in the conference (defined by the `track` column). \n",
    "\n",
    "**/Discuss:/** Using \"the logic\" of hypothesis testing (see slide 29 of Lecture 4), how would you devise a statistical test to refute the following null hypothesis: all tracks have the same fraction of papers with rebuttals. Your statistical test should consider all categories at once, rather than comparing the fraction of rebuttals between pairs of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dialogue and Interactive Systems                                0.775281\n",
       "Discourse and Pragmatics                                        0.804348\n",
       "Document Analysis                                               0.730000\n",
       "Generation                                                      0.779661\n",
       "Information Extraction and Text Mining                          0.768362\n",
       "Linguistic Theories Cognitive Modeling and Psycholinguistics    0.750000\n",
       "Machine Learning                                                0.808696\n",
       "Machine Translation                                             0.820755\n",
       "Multidisciplinary and Area Chair COI                            0.680000\n",
       "Multilinguality                                                 0.806452\n",
       "Phonology Morphology and Word Segmentation                      0.851852\n",
       "Question Answering                                              0.728395\n",
       "Resources and Evaluation                                        0.732394\n",
       "Sentence-level semantics                                        0.788889\n",
       "Sentiment Analysis and Argument Mining                          0.788235\n",
       "Social Media                                                    0.737705\n",
       "Summarization                                                   0.745098\n",
       "Tagging Chunking Syntax and Parsing                             0.770492\n",
       "Textual Inference and Other Areas of Semantics                  0.771930\n",
       "Vision Robotics Multimodal Grounding and Speech                 0.811321\n",
       "Word-level Semantics                                            0.860759\n",
       "Name: track, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rebuttal = df[df['had_rebuttal'] == 1]\n",
    "df_rebutal_perc_track = df_rebuttal['track'].value_counts() / df['track'].value_counts()\n",
    "df_rebutal_perc_track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare one by one, filtering out the data being compared (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50275647",
   "metadata": {},
   "source": [
    "## Task 2 (10pts): Prediction\n",
    "\n",
    "You decide to investigate further the effect of rebuttals on acceptance using your machine learning skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578baafa",
   "metadata": {},
   "source": [
    "\n",
    "**2.1** For each possible value in the `track` column, create a new column called {track}-onehot (e.g., for track=Generation, create Generation-onehot). Collectively, these new columns should \"one hot-encode\" the track column---for instance, if for a given paper the `track` column is filled with the value \"Generation\", the Generation-onehot column should equal 1 and all other {track}-onehot columns should equal 0. \n",
    "\n",
    "Print the column names of the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use one hot encoding to encode the categorical variables found in column track, naming the new columns as <track_name>-onehot\n",
    "df_encoded = pd.get_dummies(df['track'], prefix='', prefix_sep='')\n",
    "\n",
    "# Rename the columns\n",
    "df_encoded.columns = [f\"{col}-onehot\" for col in df_encoded.columns]\n",
    "\n",
    "# Concatenate the original DataFrame with the encoded columns\n",
    "df_one_hot = pd.concat([df, df_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>track</th>\n",
       "      <th>scores_before</th>\n",
       "      <th>scores_after</th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_after_std</th>\n",
       "      <th>Dialogue and Interactive Systems-onehot</th>\n",
       "      <th>Discourse and Pragmatics-onehot</th>\n",
       "      <th>Document Analysis-onehot</th>\n",
       "      <th>Generation-onehot</th>\n",
       "      <th>Information Extraction and Text Mining-onehot</th>\n",
       "      <th>Linguistic Theories Cognitive Modeling and Psycholinguistics-onehot</th>\n",
       "      <th>Machine Learning-onehot</th>\n",
       "      <th>Machine Translation-onehot</th>\n",
       "      <th>Multidisciplinary and Area Chair COI-onehot</th>\n",
       "      <th>Multilinguality-onehot</th>\n",
       "      <th>Phonology Morphology and Word Segmentation-onehot</th>\n",
       "      <th>Question Answering-onehot</th>\n",
       "      <th>Resources and Evaluation-onehot</th>\n",
       "      <th>Sentence-level semantics-onehot</th>\n",
       "      <th>Sentiment Analysis and Argument Mining-onehot</th>\n",
       "      <th>Social Media-onehot</th>\n",
       "      <th>Summarization-onehot</th>\n",
       "      <th>Tagging Chunking Syntax and Parsing-onehot</th>\n",
       "      <th>Textual Inference and Other Areas of Semantics-onehot</th>\n",
       "      <th>Vision Robotics Multimodal Grounding and Speech-onehot</th>\n",
       "      <th>Word-level Semantics-onehot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>P772</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Word-level Semantics</td>\n",
       "      <td>{'1': 4, '3': 4}</td>\n",
       "      <td>{'1': 4, '3': 4}</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>P499</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>{'1': 1}</td>\n",
       "      <td>{'1': 1}</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmp_id  status                 track     scores_before      scores_after  \\\n",
       "771   P772  Reject  Word-level Semantics  {'1': 4, '3': 4}  {'1': 4, '3': 4}   \n",
       "498   P499  Reject     Document Analysis          {'1': 1}          {'1': 1}   \n",
       "\n",
       "     had_rebuttal  overall_score_before_avg  overall_score_before_std  \\\n",
       "771          True                       4.0                       0.0   \n",
       "498         False                       1.0                       0.0   \n",
       "\n",
       "     overall_score_after_avg  overall_score_after_std  \\\n",
       "771                      4.0                      0.0   \n",
       "498                      1.0                      0.0   \n",
       "\n",
       "     Dialogue and Interactive Systems-onehot  Discourse and Pragmatics-onehot  \\\n",
       "771                                        0                                0   \n",
       "498                                        0                                0   \n",
       "\n",
       "     Document Analysis-onehot  Generation-onehot  \\\n",
       "771                         0                  0   \n",
       "498                         1                  0   \n",
       "\n",
       "     Information Extraction and Text Mining-onehot  \\\n",
       "771                                              0   \n",
       "498                                              0   \n",
       "\n",
       "     Linguistic Theories Cognitive Modeling and Psycholinguistics-onehot  \\\n",
       "771                                                  0                     \n",
       "498                                                  0                     \n",
       "\n",
       "     Machine Learning-onehot  Machine Translation-onehot  \\\n",
       "771                        0                           0   \n",
       "498                        0                           0   \n",
       "\n",
       "     Multidisciplinary and Area Chair COI-onehot  Multilinguality-onehot  \\\n",
       "771                                            0                       0   \n",
       "498                                            0                       0   \n",
       "\n",
       "     Phonology Morphology and Word Segmentation-onehot  \\\n",
       "771                                                  0   \n",
       "498                                                  0   \n",
       "\n",
       "     Question Answering-onehot  Resources and Evaluation-onehot  \\\n",
       "771                          0                                0   \n",
       "498                          0                                0   \n",
       "\n",
       "     Sentence-level semantics-onehot  \\\n",
       "771                                0   \n",
       "498                                0   \n",
       "\n",
       "     Sentiment Analysis and Argument Mining-onehot  Social Media-onehot  \\\n",
       "771                                              0                    0   \n",
       "498                                              0                    0   \n",
       "\n",
       "     Summarization-onehot  Tagging Chunking Syntax and Parsing-onehot  \\\n",
       "771                     0                                           0   \n",
       "498                     0                                           0   \n",
       "\n",
       "     Textual Inference and Other Areas of Semantics-onehot  \\\n",
       "771                                                  0       \n",
       "498                                                  0       \n",
       "\n",
       "     Vision Robotics Multimodal Grounding and Speech-onehot  \\\n",
       "771                                                  0        \n",
       "498                                                  0        \n",
       "\n",
       "     Word-level Semantics-onehot  \n",
       "771                            1  \n",
       "498                            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_hot.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa41ea",
   "metadata": {},
   "source": [
    "\n",
    "**2.2** Create a column `had_rebuttal_int`, which equals 1 if the paper had a rebuttal, and 0 otherwise, and a column `accepted_int`, which equals 1 if the paper was accepted, and 0 otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>track</th>\n",
       "      <th>scores_before</th>\n",
       "      <th>scores_after</th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_after_std</th>\n",
       "      <th>Dialogue and Interactive Systems-onehot</th>\n",
       "      <th>Discourse and Pragmatics-onehot</th>\n",
       "      <th>Document Analysis-onehot</th>\n",
       "      <th>Generation-onehot</th>\n",
       "      <th>Information Extraction and Text Mining-onehot</th>\n",
       "      <th>Linguistic Theories Cognitive Modeling and Psycholinguistics-onehot</th>\n",
       "      <th>Machine Learning-onehot</th>\n",
       "      <th>Machine Translation-onehot</th>\n",
       "      <th>Multidisciplinary and Area Chair COI-onehot</th>\n",
       "      <th>Multilinguality-onehot</th>\n",
       "      <th>Phonology Morphology and Word Segmentation-onehot</th>\n",
       "      <th>Question Answering-onehot</th>\n",
       "      <th>Resources and Evaluation-onehot</th>\n",
       "      <th>Sentence-level semantics-onehot</th>\n",
       "      <th>Sentiment Analysis and Argument Mining-onehot</th>\n",
       "      <th>Social Media-onehot</th>\n",
       "      <th>Summarization-onehot</th>\n",
       "      <th>Tagging Chunking Syntax and Parsing-onehot</th>\n",
       "      <th>Textual Inference and Other Areas of Semantics-onehot</th>\n",
       "      <th>Vision Robotics Multimodal Grounding and Speech-onehot</th>\n",
       "      <th>Word-level Semantics-onehot</th>\n",
       "      <th>accepted_int</th>\n",
       "      <th>had_rebuttal_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>P934</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>{'1': 4, '2': 2}</td>\n",
       "      <td>{'1': 4, '2': 4}</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>P95</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Vision Robotics Multimodal Grounding and Speech</td>\n",
       "      <td>{'1': 3, '2': 2, '3': 4}</td>\n",
       "      <td>{'1': 3, '2': 2, '3': 3}</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmp_id  status                                            track  \\\n",
       "933   P934  Accept                                     Social Media   \n",
       "94     P95  Reject  Vision Robotics Multimodal Grounding and Speech   \n",
       "\n",
       "                scores_before              scores_after  had_rebuttal  \\\n",
       "933          {'1': 4, '2': 2}          {'1': 4, '2': 4}          True   \n",
       "94   {'1': 3, '2': 2, '3': 4}  {'1': 3, '2': 2, '3': 3}          True   \n",
       "\n",
       "     overall_score_before_avg  overall_score_before_std  \\\n",
       "933                       3.0                  1.000000   \n",
       "94                        3.0                  0.816497   \n",
       "\n",
       "     overall_score_after_avg  overall_score_after_std  \\\n",
       "933                 4.000000                 0.000000   \n",
       "94                  2.666667                 0.471405   \n",
       "\n",
       "     Dialogue and Interactive Systems-onehot  Discourse and Pragmatics-onehot  \\\n",
       "933                                        0                                0   \n",
       "94                                         0                                0   \n",
       "\n",
       "     Document Analysis-onehot  Generation-onehot  \\\n",
       "933                         0                  0   \n",
       "94                          0                  0   \n",
       "\n",
       "     Information Extraction and Text Mining-onehot  \\\n",
       "933                                              0   \n",
       "94                                               0   \n",
       "\n",
       "     Linguistic Theories Cognitive Modeling and Psycholinguistics-onehot  \\\n",
       "933                                                  0                     \n",
       "94                                                   0                     \n",
       "\n",
       "     Machine Learning-onehot  Machine Translation-onehot  \\\n",
       "933                        0                           0   \n",
       "94                         0                           0   \n",
       "\n",
       "     Multidisciplinary and Area Chair COI-onehot  Multilinguality-onehot  \\\n",
       "933                                            0                       0   \n",
       "94                                             0                       0   \n",
       "\n",
       "     Phonology Morphology and Word Segmentation-onehot  \\\n",
       "933                                                  0   \n",
       "94                                                   0   \n",
       "\n",
       "     Question Answering-onehot  Resources and Evaluation-onehot  \\\n",
       "933                          0                                0   \n",
       "94                           0                                0   \n",
       "\n",
       "     Sentence-level semantics-onehot  \\\n",
       "933                                0   \n",
       "94                                 0   \n",
       "\n",
       "     Sentiment Analysis and Argument Mining-onehot  Social Media-onehot  \\\n",
       "933                                              0                    1   \n",
       "94                                               0                    0   \n",
       "\n",
       "     Summarization-onehot  Tagging Chunking Syntax and Parsing-onehot  \\\n",
       "933                     0                                           0   \n",
       "94                      0                                           0   \n",
       "\n",
       "     Textual Inference and Other Areas of Semantics-onehot  \\\n",
       "933                                                  0       \n",
       "94                                                   0       \n",
       "\n",
       "     Vision Robotics Multimodal Grounding and Speech-onehot  \\\n",
       "933                                                  0        \n",
       "94                                                   1        \n",
       "\n",
       "     Word-level Semantics-onehot  accepted_int  had_rebuttal_int  \n",
       "933                            0             1                 1  \n",
       "94                             0             0                 1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_hot['accepted_int'] = df_one_hot['status'].apply(lambda x: 1 if x == 'Accept' else 0)\n",
    "df_one_hot['had_rebuttal_int'] = df_one_hot['had_rebuttal'].apply(lambda x: 1 if x == True else 0)\n",
    "df_one_hot.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5806400",
   "metadata": {},
   "source": [
    "**2.3** Create a function `numpy_helper(df, cols)` to obtain a numpy.array out of your dataframe. The function should receive a dataframe `df` with N rows and a list of M columns `cols`, and should return a `np.array` of dimension `(NxM)` cast as a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_helper(df, cols):\n",
    "    # Select the specified columns from the dataframe\n",
    "    selected_df = df[cols]\n",
    "    \n",
    "    # Convert the selected dataframe to a numpy array and cast it as float\n",
    "    numpy_array = selected_df.to_numpy(dtype=float)\n",
    "    \n",
    "    return numpy_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dad455",
   "metadata": {},
   "source": [
    "\n",
    "**2.4**\n",
    "Create:\n",
    "- an array of features X containing all track one-hot features, as well as the `overall_score_before_avg`,`overall_score_before_std`, and `had_rebuttal_int`;\n",
    "- an array of outcomes y containing `accepted_int`. \n",
    "\n",
    "\n",
    "Print the shapes of both X and y (e.g., `X.shape`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1538, 24)\n",
      "y shape: (1538, 1)\n"
     ]
    }
   ],
   "source": [
    "one_hot_cols = [col for col in df_one_hot.columns if '-onehot' in col]\n",
    "features = ['overall_score_before_avg', 'overall_score_before_std', 'had_rebuttal_int'] + one_hot_cols\n",
    "X = numpy_helper(df_one_hot, features)\n",
    "y = numpy_helper(df_one_hot, ['accepted_int'])\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf79a4",
   "metadata": {},
   "source": [
    "\n",
    "**2.5** Build two `GradientBoostingClassifier` models using `sklearn` using the default parameters:\n",
    "- Model 1: predicts the outcome `accepted_int` using the onehot encoded features related to track, as well as the `overall_score_before_avg`,`overall_score_before_std`.\n",
    "- Model 2:  predicts the outcome `accepted_int` using the onehot encoded features related to track, as well as the `overall_score_before_avg`,`overall_score_before_std` **and** `had_rebuttal_int`.\n",
    "\n",
    "\n",
    "For both models:\n",
    "\n",
    "- Use the `cross_validate` function from `sklearn.model_selection` to compute the average precision, recall, and accuracy across test cross validation splits.\n",
    "\n",
    "    - e.g., `cross_validate(clf, X, y, cv=30, scoring=('accuracy', 'precision', 'recall'))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_boost_clf(df, cols):\n",
    "    X,y = df[cols], df['accepted_int'].ravel()\n",
    "    clf = GradientBoostingClassifier()\n",
    "    return cross_validate(clf, X, y, cv=30, scoring=['accuracy', 'precision', 'recall', 'f1'],return_train_score=True)\n",
    "\n",
    "def print_results(cv_results):\n",
    "    for metric in cv_results.keys():\n",
    "        print(f\"{metric}: {cv_results[metric].mean()} (std: {cv_results[metric].std()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = [col for col in df_one_hot.columns if '-onehot' in col]\n",
    "features_base = ['overall_score_before_avg', 'overall_score_before_std'] + one_hot_cols\n",
    "features_dev = ['had_rebuttal_int'] + features_base\n",
    "\n",
    "cv_results_base = grad_boost_clf(df_one_hot, features_base)\n",
    "cv_results_dev = grad_boost_clf(df_one_hot, features_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:\n",
      "fit_time: 0.180503511428833 (std: 0.059925440592484586)\n",
      "score_time: 0.006032721201578776 (std: 0.0023112015408422244)\n",
      "test_accuracy: 0.8373303167420816 (std: 0.040621741013475474)\n",
      "train_accuracy: 0.8675171510350057 (std: 0.00204333241782293)\n",
      "test_precision: 0.7085207385207386 (std: 0.11744279655723296)\n",
      "train_precision: 0.7786651538410765 (std: 0.006514229984411329)\n",
      "test_recall: 0.592948717948718 (std: 0.11531039873360703)\n",
      "train_recall: 0.6461644406724142 (std: 0.012042509585537734)\n",
      "test_f1: 0.6392412910986518 (std: 0.10062207915636157)\n",
      "train_f1: 0.7061567756533975 (std: 0.006449265958890717)\n",
      "\n",
      "Model 2:\n",
      "fit_time: 0.14457887013753254 (std: 0.032938511088940366)\n",
      "score_time: 0.004922342300415039 (std: 0.0007337996980534169)\n",
      "test_accuracy: 0.8386500754147814 (std: 0.03711351720402857)\n",
      "train_accuracy: 0.8679206781790322 (std: 0.002090118772956439)\n",
      "test_precision: 0.7126813001813002 (std: 0.1079234768368986)\n",
      "train_precision: 0.779642822018811 (std: 0.00827298094817993)\n",
      "test_recall: 0.5957264957264959 (std: 0.11259609251512649)\n",
      "train_recall: 0.6470751874848002 (std: 0.011367334085823431)\n",
      "test_f1: 0.6420162864510691 (std: 0.09327558672344727)\n",
      "train_f1: 0.7070929449857767 (std: 0.0058692459025303945)\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1:\")\n",
    "print_results(cv_results_base)\n",
    "print()\n",
    "print(\"Model 2:\")\n",
    "print_results(cv_results_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abba6d4",
   "metadata": {},
   "source": [
    "\n",
    "**2.6** Determine whether the difference in accuracy of the two models is statistically significant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 accuracy:  0.8373303167420816\n",
      "Model 2 accuracy:  0.8386500754147814\n",
      "p-value:  0.897673080747567\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1 accuracy: \", cv_results_base['test_accuracy'].mean())\n",
    "print(\"Model 2 accuracy: \", cv_results_dev['test_accuracy'].mean())\n",
    "#do t test to see if the difference in accuracy is significant\n",
    "from scipy.stats import ttest_ind\n",
    "coef, p_val = ttest_ind(cv_results_base['test_accuracy'], cv_results_dev['test_accuracy'])\n",
    "print(\"p-value: \", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mean of cross vlaidation accuracies are near identical, to prove the resemblance of these numbers, we could conduct a t-test on the accuracy values obtained and find that not only are the means similar, but p-value = 0.89 founding that the null hypothesis (these are identical distributions) holds well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9518f2f6",
   "metadata": {},
   "source": [
    "**2.7** **/Discuss:/** Contrast the results obtained in **2.6** with what you observed in **Task 1**. What advantage did the analyses in **2.6** have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In task one we gained an insight on the correlation between the number of points scored and the ditribution on the possibility of having your paper accepted. However there was a lot of **overlaping** in the graphs. \n",
    "\n",
    "- This time we have the knowledge of the domain in which the paper has been written and can thus add the domain specific information obtained this way. \n",
    "- We see that the fact of having a rebutal or **not doesn't exactly change** the decision accuracy afteer all, proving that is actually **not an important feature** and could be discarded (at least when working with a gradient booster classifier) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52beb97e",
   "metadata": {},
   "source": [
    "## Task 3 (12pts): Interlude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f56eca",
   "metadata": {},
   "source": [
    "\n",
    "**3.1** Using the formula API from `statsmodels`, estimate the following linear regressions. Report the summary of the models.\n",
    "- `accepted_int ~ had_rebuttal_int`,  \n",
    "- `accepted_int ~ overall_score_after_avg`\n",
    "- `had_rebuttal_int ~ overall_score_before_avg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: accepted_int ~ had_rebuttal_int\n",
    "model_1 = smf.ols('accepted_int ~ had_rebuttal_int', data=df_one_hot)\n",
    "result_1 = model_1.fit()\n",
    "\n",
    "# Model 2: accepted_int ~ overall_score_after_avg\n",
    "model_2 = smf.ols('accepted_int ~ overall_score_after_avg', data=df_one_hot)\n",
    "result_2 = model_2.fit()\n",
    "\n",
    "# Model 3: had_rebuttal_int ~ overall_score_before_avg\n",
    "model_3 = smf.ols('had_rebuttal_int ~ overall_score_before_avg', data=df_one_hot)\n",
    "result_3 = model_3.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: accepted_int ~ had_rebuttal_int\n",
      "dependance of acceptance on rebuttal\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           accepted_int   R-squared:                       0.041\n",
      "Model:                            OLS   Adj. R-squared:                  0.041\n",
      "Method:                 Least Squares   F-statistic:                     66.22\n",
      "Date:                Tue, 21 Nov 2023   Prob (F-statistic):           8.24e-16\n",
      "Time:                        21:28:24   Log-Likelihood:                -855.16\n",
      "No. Observations:                1538   AIC:                             1714.\n",
      "Df Residuals:                    1536   BIC:                             1725.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            0.0838      0.023      3.693      0.000       0.039       0.128\n",
      "had_rebuttal_int     0.2098      0.026      8.138      0.000       0.159       0.260\n",
      "==============================================================================\n",
      "Omnibus:                      271.753   Durbin-Watson:                   1.920\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              324.377\n",
      "Skew:                           1.075   Prob(JB):                     3.65e-71\n",
      "Kurtosis:                       2.336   Cond. No.                         4.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Display model summaries\n",
    "print(\"Model 1: accepted_int ~ had_rebuttal_int\")\n",
    "print(\"dependance of acceptance on rebuttal\")\n",
    "print(result_1.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2: accepted_int ~ overall_score_after_avg\n",
      "dependance of acceptance on overall score after rebuttal\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           accepted_int   R-squared:                       0.402\n",
      "Model:                            OLS   Adj. R-squared:                  0.401\n",
      "Method:                 Least Squares   F-statistic:                     1031.\n",
      "Date:                Tue, 21 Nov 2023   Prob (F-statistic):          1.58e-173\n",
      "Time:                        21:28:24   Log-Likelihood:                -492.65\n",
      "No. Observations:                1538   AIC:                             989.3\n",
      "Df Residuals:                    1536   BIC:                             1000.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -0.6558      0.029    -22.339      0.000      -0.713      -0.598\n",
      "overall_score_after_avg     0.2860      0.009     32.111      0.000       0.269       0.303\n",
      "==============================================================================\n",
      "Omnibus:                      110.778   Durbin-Watson:                   1.927\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               51.680\n",
      "Skew:                           0.256   Prob(JB):                     5.99e-12\n",
      "Kurtosis:                       2.263   Cond. No.                         12.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel 2: accepted_int ~ overall_score_after_avg\")\n",
    "print(\"dependance of acceptance on overall score after rebuttal\")\n",
    "print(result_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 3: had_rebuttal_int ~ overall_score_before_avg\n",
      "dependance of rebuttal on score before rebuttal\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       had_rebuttal_int   R-squared:                       0.135\n",
      "Model:                            OLS   Adj. R-squared:                  0.135\n",
      "Method:                 Least Squares   F-statistic:                     240.2\n",
      "Date:                Tue, 21 Nov 2023   Prob (F-statistic):           1.89e-50\n",
      "Time:                        21:28:24   Log-Likelihood:                -727.42\n",
      "No. Observations:                1538   AIC:                             1459.\n",
      "Df Residuals:                    1536   BIC:                             1470.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "Intercept                    0.2527      0.035      7.195      0.000       0.184       0.322\n",
      "overall_score_before_avg     0.1651      0.011     15.499      0.000       0.144       0.186\n",
      "==============================================================================\n",
      "Omnibus:                      201.621   Durbin-Watson:                   1.930\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              288.526\n",
      "Skew:                          -1.060   Prob(JB):                     2.23e-63\n",
      "Kurtosis:                       2.890   Cond. No.                         12.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel 3: had_rebuttal_int ~ overall_score_before_avg\")\n",
    "print(\"dependance of rebuttal on score before rebuttal\")\n",
    "print(result_3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc5e23",
   "metadata": {},
   "source": [
    "\n",
    "**3.2** **/Discuss:/** Interpret the coefficients associated with the binary independent variable in the above models. Note that independent variables are the ones on the right-handside of the equation.\n",
    "\n",
    "- e.g., in `had_rebuttal_int ~ overall_score_before_avg`, `overall_score_before_avg` is the independent variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 1: accepted_int =  0.2098 * had_rebuttal_int + 0.0838\n",
    "- The only model out of the three that uses a binary independant vatiable is the first one. We see in the equation above that the fact of having a rebuttal seems to add on its own a 0.2 = 1/5 chance of having the paper accepted.\n",
    "\n",
    "\n",
    "- Model 3: had_rebuttal_int = 0.1651 * overall_score_before_avg + 0.2527"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba81dc",
   "metadata": {},
   "source": [
    "\n",
    "**3.3** **/Discuss:/** describe three correlations you can draw from the previous analysis. Describe their sign (i.e., whether they are positive or negative), and whether they are statistically significant (at the .05 level of significance).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all corelations seem to be positive\n",
    "\n",
    "- in addition to that, the p values of the coeficients apear to be very close to zero, thus indicating that these coeficients are of statistically significant value. \n",
    "\n",
    "- as said in the previous answer, the coeficient of having a rebuttal is 0.2 and the intercept here is 0.08, signifying a measurrable difference, having a rebuttal or not. Yet still having the final value not exeeding 0.3 which indicates a probabilaty of rather not being accepted than accepted. \n",
    "\n",
    "- Model 2: accepted_int = 0.2860 * overall_score_after_avg - 0.6558 \n",
    "for model 2, we see that the intercept term is negative, of -0.65. In the same time, the coef associated with the score obtained is 0.28. Together this would mean that at a score of 5/5 we are yet to reach 1 but find the value of 0.7742. Overall, this shows that even though the acceptance is even more correlated with a high score, there are other factors to count for. \n",
    "\n",
    "- Model 3: had_rebuttal_int = 0.1651 * overall_score_before_avg + 0.2527\n",
    "Finally, in this model, the intercept value of 0.25 indicates that even with a low score,thre is a probabilaty of having a rebuttal. As sujested earlier (in part 1), reebuttals seemed to occur more often together with higher scores and this is exactly the tendancy that's proved by the posititve coeficient of overall_score_before_avg. In the case of a score being equal to 5, we even ecceed the value of 1 for the predicted had_rebuttal_int value. Thus we could be sure that papers with high scores will have a high probabilaty of having a rebuttal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa59821c",
   "metadata": {},
   "source": [
    "**3.4** **/Discuss:/** Is the following statement True or False? Justify. \n",
    "\n",
    "- The variable `overall_score_after_avg` explains more of the variance in `accepted_int` than the variable `overall_score_before_avg` explains of `had_rebuttal_int`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have that R-squared is the variance caused in the dependant variable by variations in the independant variable. Since both are the same type of independant variable (between 0 and 5), we directly see that `accepted_int` has 0.4 = 40% of variance expressed by `overall_score_after_avg`, while `overall_score_before_avg` has 0.135 = 13.5% ov variance on `had_rebuttal_int`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405fb7f",
   "metadata": {},
   "source": [
    "\n",
    "**3.5** **/Discuss:/** Create a causal diagram relating the following variables:\n",
    "- \"Sa\": `overall_score_after_avg`\n",
    "- \"Sb\": `overall_score_before_avg`\n",
    "- \"Re\": `had_rebuttal_int`\n",
    "- \"Ac\": `accepted_int`\n",
    "- \"Tr\": `track`\n",
    "\n",
    "\n",
    "When unsure about whether a causal relationship exists, include it in the diagram. E.g., include the arrow corresponding to the key questions around this homework, i.e., `had_rebuttal_int`->`accepted_int`, even though you are investigating whether it exists. \n",
    "\n",
    "You may draw your diagram using text, use Sa/Sb/Re/Ac/Tr to represent the names of the variables, and simply indicate the causal links, one per line.\n",
    "\n",
    "\n",
    "Instead of drawing something like this:\n",
    "![](./dagv.jpeg)\n",
    "\n",
    "Simply write:\n",
    "\n",
    "- Tr->Sb\n",
    "- Tr->Ac\n",
    "- Tr->Re\n",
    "- Ac->Sb\n",
    "- Re->Sb\n",
    "- Sb->Sa\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tr -> Sb\n",
    "- Tr -> Sa\n",
    "- Tr -> Ac\n",
    "\n",
    "- Sb -> Sa\n",
    "- Sb -> Re\n",
    "\n",
    "- Re -> Sa\n",
    "\n",
    "- Sa -> Ac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe89c00",
   "metadata": {},
   "source": [
    "**3.6** **/Discuss:/** What is the problem of simply comparing the outcomes of papers that had rebuttals with those that did not? Give a concrete example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the following are percetages of tracks that have a p-value less than 0.05 for different metrics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "overall_score_before_avg    0.238095\n",
       "overall_score_after_avg     0.142857\n",
       "overall_score_after_std     0.428571\n",
       "overall_score_before_std    0.190476\n",
       "had_rebuttal_int            0.047619\n",
       "accepted_int                0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "cols_to_test = ['overall_score_before_avg', 'overall_score_after_avg','overall_score_after_std','overall_score_before_std' ,'had_rebuttal_int', 'accepted_int']\n",
    "#create a dataframe with row iindicess as track names and columns as the p-values for each column in cols_to_test\n",
    "p_values = pd.DataFrame(index=df_one_hot['track'].unique(), columns=cols_to_test)\n",
    "for col in cols_to_test:\n",
    "    for track in df_one_hot['track'].unique():\n",
    "        test_group = df_one_hot[df_one_hot['track'] == track]\n",
    "        other_group = df_one_hot[df_one_hot['track'] != track]\n",
    "        _,p_value = stats.ttest_ind(test_group[col], other_group[col])\n",
    "        p_values.loc[track, col] = p_value\n",
    "#in each column, count the number of p-values that are less than 0.05\n",
    "p_values = p_values.apply(lambda x: x < 0.05).sum()\n",
    "p_values_percetages = p_values.apply(lambda x: x/len(df_one_hot['track'].unique()))\n",
    "print(\"the following are percetages of tracks that have a p-value less than 0.05 for different metrics\")\n",
    "p_values_percetages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposing that there is a cofounder represented by the track, we find ourselfs with a rather biased set, where depending on the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed68a4",
   "metadata": {},
   "source": [
    "# Task 4 (12 pts): Observational study\n",
    "\n",
    "You decide to use your observational study skills to obtain a concrete answer to the question: do rebuttals increase acceptance?\n",
    "\n",
    " **4.1** Perform exact one-to-one matching considering the `overall_score_before_avg` and the `track` variables. Each paper that had a rebuttal (\"treatment group\") should be matched to a paper that did not have a rebuttal (\"control group\"). \n",
    "- Your matching should be optimal, i.e., the maximum amount of papers possible must be matched. \n",
    "- Print the dataframe of papers in the matched sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192\n",
      "0.7750325097529259\n"
     ]
    }
   ],
   "source": [
    "print(df_one_hot['had_rebuttal'].sum())\n",
    "print(df_one_hot['had_rebuttal'].sum()/len(df_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "df = df_one_hot.copy()\n",
    "cols = [col for col in df_one_hot.columns if '-onehot' in col]+ ['overall_score_before_avg']\n",
    "X = df_one_hot[cols]  # Include relevant covariates\n",
    "y = df_one_hot['had_rebuttal_int'] # Outcome variable\n",
    "\n",
    "propensity_model = LogisticRegression()\n",
    "propensity_model.fit(X, y)\n",
    "\n",
    "# Predict propensity scores\n",
    "df['propensity_score'] = propensity_model.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-32e25523cb8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Perform matching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmatching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_weight_matching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mmatched_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__wrapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0margmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;31m# standard function-wrapping stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36margmap_max_weight_matching_1\u001b[0;34m(G, maxcardinality, weight)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/algorithms/matching.py\u001b[0m in \u001b[0;36mmax_weight_matching\u001b[0;34m(G, maxcardinality, weight)\u001b[0m\n\u001b[1;32m    976\u001b[0m                         \u001b[0;31m# keep track of the least-slack non-allowable edge to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                         \u001b[0;31m# a different S-blossom.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mbestedge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkslack\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mslack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbestedge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m                             \u001b[0mbestedge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/algorithms/matching.py\u001b[0m in \u001b[0;36mslack\u001b[0;34m(v, w)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;31m# Return 2 * slack of edge (v, w) (does not work inside blossoms).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdualvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdualvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;31m# Assign label t to the top-level blossom containing vertex w,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a graph with nodes representing units and edges representing potential matches\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with propensity scores as attributes\n",
    "for index, row in df.iterrows():\n",
    "    G.add_node(index, propensity_score=row['propensity_score'])\n",
    "\n",
    "# Add edges based on propensity score differences\n",
    "for i in df.index:\n",
    "    for j in df.index:\n",
    "        if i != j:\n",
    "            G.add_edge(i, j, weight=abs(df.loc[i, 'propensity_score'] - df.loc[j, 'propensity_score']))\n",
    "\n",
    "# Perform matching\n",
    "matching = nx.max_weight_matching(G)\n",
    "matched_df = df.loc[list(matching.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31c97d1",
   "metadata": {},
   "source": [
    "**4.2** So far, we did not consider the `overall_score_before_std` variable. One could argue that the variance in the scores makes a difference. E.g., a paper that received scores 1 and 5, might be very different from a paper with scores 3 and 3. \n",
    "\n",
    "Note that you did not match on the `overall_score_before_std` variable. However, it suffices if this variable is \"balanced\" across treatment and control groups.\n",
    " Use the Standardized Mean Difference (SMD) to assess whether that's the case.\n",
    "\n",
    "- The standardized mean difference for a variable $x$ and two groups $t$ and $c$ is defined as: $\\frac{| E[x_t] - E[x_c] |}{\\sqrt{Var[x_t] + Var[x_c]}}$\n",
    "\n",
    "- Note that a Standardized Mean Difference smaller than 0.1 suggests that variables are balanced across treatment and control groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claculate the expected value of score_before_avg for elements with had_rebuttal = 1 and had_rebuttal = 0\n",
    "e_reb = matched_df[matched_df['had_rebuttal'] == 1]['overall_score_before_avg'].mean()\n",
    "e_no_reb = matched_df[matched_df['had_rebuttal'] == 0]['overall_score_before_avg'].mean()\n",
    "var_reb = matched_df[matched_df['had_rebuttal'] == 1]['overall_score_before_avg'].var()\n",
    "var_no_reb = matched_df[matched_df['had_rebuttal'] == 0]['overall_score_before_avg'].var()\n",
    "smd = np.abs(e_reb - e_no_reb) / np.sqrt(var_reb + var_no_reb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f788c",
   "metadata": {},
   "source": [
    "\n",
    "**4.3** Using the matched sample, estimate the following linear regression: `accepted ~ had_rebuttal_int`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model : accepted_int ~ had_rebuttal_int tested on the matched data\n",
    "model = smf.ols('accepted_int ~ had_rebuttal_int', data=matched_df)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8423e",
   "metadata": {},
   "source": [
    "\n",
    "**4.4** **/Discuss:/**\n",
    "\n",
    "i. Considering your results obtained in 4.3, and the causal diagram drawn in Task 3: do rebuttals increase the chance of a paper getting accepted? Why are results different from what you obtained in **Task 1?**\n",
    "\n",
    "ii. Why is there no need to include other covariates (e.g., score before) in the regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4867ea1",
   "metadata": {},
   "source": [
    "**4.5** **/Discuss:/** Imagine there is another, unobserved variable \"quality\" which captures the true quality of the paper. Suppose quality (\"Qu\") is connected to the DAG you drew in the following ways:\n",
    "- Qu -> Sa\n",
    "- Qu -> Sb\n",
    "- Qu -> Re\n",
    "- Qu -> Ac\n",
    "Assume that\n",
    "- quality can only increase the chances of rebuttals;\n",
    "- quality and the rebuttal can only increase the chance of a paper being accepted.\n",
    "Does this uncontrolled confounder threaten the validity of your findings?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
